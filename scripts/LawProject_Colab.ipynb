{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Google Drive 마운트 (필수)\n",
                "모델 파일(약 5GB 이상)을 매번 다운로드하지 않기 위해 Google Drive를 연결합니다.\n",
                "또한 프로젝트 파일(`law_project.zip`)을 불러오는 용도로도 사용됩니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from google.colab import drive\n",
                "import os\n",
                "\n",
                "if not os.path.exists(\"/content/drive\"):\n",
                "    drive.mount(\"/content/drive\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 환경 설정 및 Ollama 설치\n",
                "Linux용 Ollama 바이너리와 필요한 Python 패키지를 설치합니다.\n",
                "**GPU 감지 도구(pciutils) 포함**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install System Dependencies (Fix missing zstd, pciutils)\n",
                "!sudo apt-get update && sudo apt-get install -y zstd pciutils lshw\n",
                "# Check GPU status\n",
                "!nvidia-smi\n",
                "\n",
                "# 2. Install Ollama\n",
                "!curl -fsSL https://ollama.com/install.sh | sh\n",
                "\n",
                "# 3. Install Python Dependencies for Web & Tunneling\n",
                "!pip install pyngrok uvicorn nest_asyncio"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Start Ollama Server in Background (Local Execution)\n",
                "import subprocess\n",
                "import time\n",
                "import os\n",
                "import requests\n",
                "\n",
                "# [안정성 수정] Google Drive 직접 실행 대신 로컬 실행으로 변경 (충돌 방지)\n",
                "DRIVE_MODEL_PATH = \"/content/drive/MyDrive/OllamaModels\"\n",
                "LOCAL_MODEL_PATH = \"/usr/share/ollama/.ollama/models\" # Default path or ~/.ollama\n",
                "\n",
                "# Ollama server start (Clean environment)\n",
                "if \"OLLAMA_MODELS\" in os.environ:\n",
                "    del os.environ[\"OLLAMA_MODELS\"]\n",
                "\n",
                "print(\"Starting Ollama server...\")\n",
                "process = subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
                "\n",
                "# Wait for Ollama to become ready with Timeout\n",
                "max_retries = 20\n",
                "print(\"Waiting for Ollama to start...\")\n",
                "for i in range(max_retries):\n",
                "    try:\n",
                "        response = requests.get(\"http://localhost:11434\")\n",
                "        if response.status_code == 200:\n",
                "            print(\"Ollama server is running successfully!\")\n",
                "            break\n",
                "    except requests.exceptions.ConnectionError:\n",
                "        if i == max_retries - 1:\n",
                "            print(\"Failed to connect to Ollama server.\")\n",
                "            # Print potential errors\n",
                "            # Note: process.communicate() blocks, so we just peek if it's dead\n",
                "            if process.poll() is not None:\n",
                "                out, err = process.communicate()\n",
                "                print(f\"Process terminated. Out: {out}, Err: {err}\")\n",
                "        time.sleep(2)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!ollama pull qwen2.5\n",
                "!ollama pull nomic-embed-text"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. 프로젝트 파일 준비\n",
                "Google Drive에서 `law_project.zip`을 가져와 실행 환경을 구축합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import shutil\n",
                "\n",
                "DRIVE_PROJECT_PATH = \"/content/drive/MyDrive/LawProject/law_project.zip\"\n",
                "\n",
                "# 1. 이미 파일이 있으면 (재실행 시) 패스\n",
                "if os.path.exists(\"law_project.zip\"):\n",
                "    print(\"law_project.zip already exists locally.\")\n",
                "else:\n",
                "    if os.path.exists(DRIVE_PROJECT_PATH):\n",
                "        print(f\"Google Drive에서 파일을 복사합니다: {DRIVE_PROJECT_PATH}\")\n",
                "        shutil.copy(DRIVE_PROJECT_PATH, \"/content/law_project.zip\")\n",
                "    else:\n",
                "        print(\"!!! Google Drive에 파일이 없습니다. 직접 업로드를 시도합니다. !!!\")\n",
                "        from google.colab import files\n",
                "        uploaded = files.upload()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Unzip with CP949 (Korean) encoding\n",
                "!unzip -O cp949 -o law_project.zip -d /content/LawProject"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%cd /content/LawProject\n",
                "!pip install -r requirements.txt"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. 웹 서버 실행 (Ngrok)\n",
                "웹 인터페이스를 외부에서 접속할 수 있도록 `ngrok`을 설정합니다.\n",
                "**[Ngrok Dashboard](https://dashboard.ngrok.com/get-started/your-authtoken)**에서 토큰을 복사해오세요."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyngrok import ngrok\n",
                "import getpass\n",
                "\n",
                "print(\"Ngrok Authtoken을 입력하세요 (입력 시 보이지 않습니다):\")\n",
                "token = getpass.getpass()\n",
                "ngrok.set_auth_token(token)\n",
                "\n",
                "# Terminate open tunnels if any\n",
                "ngrok.kill()\n",
                "\n",
                "# Open an HTTP tunnel on port 8000\n",
                "public_url = ngrok.connect(8000)\n",
                "print(f\"\\n>>> 웹 인터페이스 접속 주소: {public_url} <<<\\n\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run FastAPI Server via Uvicorn\n",
                "import uvicorn\n",
                "import nest_asyncio\n",
                "from app.server import app\n",
                "\n",
                "# Apply nest_asyncio to allow nested event loops in Jupyter\n",
                "nest_asyncio.apply()\n",
                "\n",
                "print(\"서버를 시작합니다... 위에서 출력된 ngrok URL로 접속하세요.\")\n",
                "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}