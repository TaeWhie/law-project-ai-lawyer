# LawProject: 설계 근거 및 전략 기획서 (Design Rationale & Strategy)

본 문서는 LawProject가 단순한 챗봇을 넘어 **'신뢰할 수 있는 법률 어시스턴트'**로서 존재하기 위해 채택한 핵심 설계 의사결정과 그 논리적 배경(Rationale)을 기술합니다.

---

## 1. 프로젝트 비전: '할루시네이션 제로'를 향한 법률 AI

기존 LLM 기반 상담 시스템의 가장 큰 결함은 **전문 지식의 환각(Hallucination)**입니다. 법률 영역에서의 환각은 사용자에게 치명적인 손해를 입힐 수 있습니다. LawProject는 이를 방지하기 위해 **"AI의 지능은 빌리되, 지식은 격리한다"**는 원칙을 고수합니다.

### 1.1. 디자인 철학: RAG-Only Policy (지식의 폐쇄성)
- **결정**: LLM이 학습한 내부 지식(Pre-trained Knowledge)을 답변에 사용하지 못하도록 엄격히 제한하고, 오로지 검색된 법령 전문(RAG Context)만을 근거로 판단하게 합니다.
- **이유**: 
    - 법률은 매년 개정됩니다. 학습 데이터에 의존할 경우 구법(Old Law)에 기반한 오답을 낼 위험이 큽니다.
    - 검색된 컨텍스트만을 사용하면 **'근거 조문 제시'**가 명확해지며, 이는 사용자에게 법적 신뢰성을 주는 핵심 요소가 됩니다.

---

## 2. 기존 법률 AI/챗봇과의 차별점 (Differentiators)

LawProject는 단순한 '질의응답(Q&A)' 도구가 아닙니다. 기존 LLM 서비스나 법률 챗봇들이 해결하지 못한 한계를 다음과 같이 기술적으로 극복합니다.

### 2.1. 수동적 응답 가이드 vs 능동적 조사 엔진
- **기존 AI**: 사용자가 모든 상황을 완벽하게 설명할 때까지 기다리며, 정보가 부족하면 추측성 답변을 내놓습니다.
- **LawProject**: 법적 요건에서 누락된 사실을 **AI가 먼저 인지하고 역질문**합니다. "어떻게 오셨나요?"가 아니라 "근로계약서를 쓰셨나요?"라고 묻는 '능동적 조사(Active Investigation)' 체계를 가집니다.

### 2.2. 단순 대화 기록 vs 상태 보존형 사실 추적 (Persistent Fact Tracking)
- **기존 AI**: 대화가 길어지면 앞서 말한 사실을 잊거나 모순된 말을 할 수 있습니다. (Static context limitation)
- **LawProject**: 모든 상담 과정은 `ConversationState`라는 하드 데이터에 **정규화된 사실(`YES/NO/UNKNOWN`)**로 기록됩니다. AI가 바뀌거나 세션이 복구되어도 확인된 사실은 변하지 않는 '상태 지속성'을 보장합니다.

### 2.3. 확률적 추론 vs 법리적 인과 판정 (Evidence-Based IRAC)
- **기존 AI**: 다음에 올 가장 어울리는 단어를 예측(Next-token prediction)하여 그럴듯한 답변을 만듭니다.
- **LawProject**: **IRAC(Issue-Rule-Application-Conclusion)** 구조를 강제합니다. [이슈]가 포착되면 [조문]을 찾고, 확인된 [사실]을 대입하여 [결론]을 도출하는 정교한 알고리즘을 따릅니다.

### 2.4. 폐쇄적 학습 지식 vs 동적 법령 연결 (Hot-swappable Law Base)
- **기존 AI**: 모델이 학습된 시점의 지식에 갇혀 있습니다.
- **LawProject**: AI는 '해석 능력'만 제공할 뿐, '지식'은 외부 마크다운 파일에서 동적으로 로드됩니다. 법 개정 시 코드 수정 없이 **파일 교체만으로 0.1초 만에 최신 법률이 반영**됩니다.

---

## 3. 핵심 아키텍처 설계 근거 (Key Rationales)

### 2.1. 왜 '3단계 오케스트레이션(3-Phase Flow)'인가?
시스템은 한 번에 모든 답변을 내놓지 않고 `기초 자격(Phase 1) -> 쟁점 압축(Phase 2) -> 상세 조사(Phase 3)`의 단계를 거칩니다.

- **Rationale**:
    - **효율적 자원 배분**: 상담 자격이 없는 유저(예: 근로자가 아닌 경우)에게 상세한 임금 계산 로직을 돌리는 것은 토큰 낭비입니다.
    - **심리적 유도**: 사용자는 처음부터 복잡한 서술형 답변을 하기 어렵습니다. 기초 사실부터 차근차근 묻는 구조는 사용자 데이터의 정확도를 높입니다.
    - **법적 논리 구조 재현**: 실제 변호사가 상담할 때 "귀하가 근로자인가요?"부터 묻는 **법학적 사고 체계(IRAC)**를 시스템적으로 구현한 것입니다.

### 2.2. 왜 '원자적 사실 분해(Atomic Decomposition)'인가?
조문을 하나의 문장으로 묻지 않고, `[상시 5인 이상]`, `[1년 이상 근속]` 등 세부 요건으로 쪼개서 관리합니다.

- **Rationale**:
    - **정밀한 상태 관리**: 복합 질문("5인 이상이고 1년 넘게 일했나요?")은 사용자가 하나만 누락해도 판정이 불가능해집니다.
    - **데이터 재사용성**: 쪼개진 사실 정보는 추후 다른 법률 검토 시에도 재사용될 수 있는 '지식 자산'이 됩니다.
    - **UI 유연성**: 체크리스트 UI를 실시간으로 업데이트하여 사용자에게 '진행률'을 시각적으로 보여줄 수 있습니다.

### 2.3. 왜 '하이브리드 메타데이터 검색'인가?
단순 벡터 유사도(Semantic Search)에 의존하지 않고, 조문 번호(Regex) 필터링을 병행합니다.

- **Rationale**:
    - **고유 식별자의 정확성**: "제43조"라는 명시적 언급이 있을 때 벡터 검색은 유사한 내용의 다른 조항을 가져올 확률이 있습니다. 
    - **법률 전문가의 습관**: 전문가는 내용보다 조문 번호로 소통하는 경우가 많으므로 이를 즉각적으로 수집하여 검색 성능을 극대화합니다.

---

## 3. 기술적 명분: 확장성 및 유지보수성 (Scalability)

### 3.1. 법령 독립적 인덱싱 (Law Agnostic Indexing)
`legal_index.json`은 특정 법령에 종속되지 않는 범용 구조를 가집니다.

- **Rationale**:
    - 현재는 '근로기준법' 중심이지만, 동일한 파이프라인으로 '민법', '상법' 등 어떤 마크다운 법령 파일도 즉시 시스템에 편입시킬 수 있는 **'법률 운영 체제(Legal OS)'**를 지향합니다.

### 3.2. 멀티 모델 추상화 (LLM Factory)
OpenAI 임베딩과 Ollama 로컬 임베딩을 동시에 지원합니다.

- **Rationale**:
    - **데이터 보안**: 민감한 법률 상담 데이터를 외부 API로 보내기 꺼려하는 엔터프라이즈 환경을 고려하여, 완전 폐쇄형 로컬 환경(Air-gapped) 구축이 가능하도록 설계했습니다.
    - **비용 최적화**: 단순 분류는 로컬 모델로, 정밀 보고서 작성은 고성능 클라우드 모델로 배분하여 운영 비용을 절감합니다.

---

## 4. 기대 효과 (Business & User Value)

- **사용자**: 법률 지식 없이도 '예/아니오' 답변만으로 전문가 수준의 법리 검토 보고서를 획득.
- **개발자/운영자**: 코드 수정 없이 법령 파일 교체만으로 서비스 도메인 확장 가능.
- **사회적 가치**: 법률 서비스의 문턱을 낮추고, 1차적인 사실 확인 과정을 자동화하여 법률 인력의 업무 효율 향상.
