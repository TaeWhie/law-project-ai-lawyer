# Streamlit App
import streamlit as st
import os
import sys
import json
import time

# Add project root to sys.path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from rag.retriever import LawRetriever
from dotenv import load_dotenv

# Load env - Load this before any other logic
load_dotenv()

# --- Page Config (Must be first) ---
st.set_page_config(
    page_title="AI ë²•ë¥  ì¡°í•­ ì¶”ì²œê¸°",
    layout="wide",  # Use full width
    initial_sidebar_state="expanded"
)

# --- Streamlit Cloud Compatibility ---
# Bridge st.secrets to os.environ for LangChain
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]

# Debug: Check API Key Status
api_key_status = "âœ… ì„¤ì •ë¨" if os.getenv("OPENAI_API_KEY") else "âŒ ë¯¸ì„¤ì • (Secrets í™•ì¸ í•„ìš”)"
with st.sidebar:
    st.markdown(f"**API Key ìƒíƒœ**: {api_key_status}")
    if os.getenv("OPENAI_API_KEY"):
        st.success("API í‚¤ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.error("Secretsì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# --- Bypass Streamlit's Email Prompt ---
if "user_email" not in st.session_state:
    st.session_state.user_email = "test@example.com"

def main():
    st.title("âš–ï¸ AI ë²•ë¥  ì¡°í•­ ì¶”ì²œê¸°")
    st.markdown("---")

    # --- Initialize Retriever (Cached) ---
    if "retriever" not in st.session_state or not hasattr(st.session_state.retriever, "retrieve_grouped"):
        try:
            st.session_state.retriever = LawRetriever(
                persist_directory="data/chroma",
                collection_name="statutes"
            )
        except Exception as e:
            st.error(f"Retriever ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return

    retriever = st.session_state.retriever

    # --- Global 2-Column Layout ---
    # Left: Input & Articles
    # Right: AI Analysis
    # We use a [1, 1] split to give equal real estate, or [4, 5] for slightly wider analysis
    left_col, right_col = st.columns([1, 1], gap="large")

    with left_col:
        st.subheader("1. ìƒí™© ì„¤ëª… ë° ì¡°í•­ ê²€ìƒ‰")
        user_input = st.text_area(
            "ë²•ì  ìƒí™©ì„ ìì„¸íˆ ë¬˜ì‚¬í•´ ì£¼ì„¸ìš”:", 
            height=200,
            placeholder="ì˜ˆ: ì›”ê¸‰ì„ 3ë‹¬ì§¸ ëª» ë°›ê³  ìˆëŠ”ë° íšŒì‚¬ê°€ ë§í•  ê²ƒ ê°™ì•„ìš”."
        )
        
        search_clicked = st.button("ğŸ” ê´€ë ¨ ë²•ì•ˆ ì°¾ê¸°", use_container_width=True)
        
        st.markdown("### ğŸ“œ ê´€ë ¨ ë²•ë¥  ì¡°í•­")
        # Placeholder for articles
        article_container = st.container()

    with right_col:
        st.subheader("2. ğŸ‘¨â€âš–ï¸ AI ë³€í˜¸ì‚¬ ë¶„ì„")
        # Placeholder for analysis
        analysis_container = st.empty()
        analysis_container.info("ğŸ‘ˆ ì¢Œì¸¡ì—ì„œ ìƒí™©ì„ ì…ë ¥í•˜ê³  ê²€ìƒ‰í•˜ë©´, ë²•ë¥  ì „ë¬¸ê°€ì˜ ë¶„ì„ ê²°ê³¼ê°€ ì´ê³³ì— í‘œì‹œë©ë‹ˆë‹¤.")

    # --- Logic ---
    if search_clicked:
        if not user_input.strip():
            st.warning("ìƒí™©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            return
        
        with st.spinner("ë²•ë¥  ì¡°í•­ì„ ê²€ìƒ‰í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # 1. Retrieve Grouped Results
                # Returns Dict[str, List[Document]]
                grouped_results = retriever.retrieve_grouped(user_input, k_per_cat=3, top_k_cats=3)
                
                # 2. Display Articles (Left)
                all_docs = []
                with article_container:
                    if not grouped_results:
                        st.error("ê´€ë ¨ëœ ë²•ë¥  ì¡°í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    else:
                        for cat_name, docs in grouped_results.items():
                            st.markdown(f"#### ğŸ·ï¸ {cat_name}")
                            for i, doc in enumerate(docs):
                                all_docs.append(doc)
                                meta = doc.metadata
                                title = meta.get("Title", "ë²•ë¥ ")
                                article_full = meta.get("Article", "ì¡°í•­")
                                
                                with st.expander(f"{title} > {article_full}", expanded=False):
                                    st.markdown(f"**{article_full}**")
                                    st.code(doc.page_content, language="text")
                            st.markdown("---")
                
                # 3. Generate Analysis (Right)
                if all_docs:
                    with analysis_container:
                        try:
                            from app.llm_factory import LLMFactory
                            from langchain_core.prompts import ChatPromptTemplate
                            
                            docs_context = ""
                            # Remove duplicates for context
                            seen_articles = set()
                            for doc in all_docs:
                                art_key = f"{doc.metadata.get('Title', '')}_{doc.metadata.get('Article', '')}"
                                if art_key not in seen_articles:
                                    docs_context += f"- {doc.metadata.get('Article', '')}: {doc.page_content}\n"
                                    seen_articles.add(art_key)
                            
                            lawyer_prompt = ChatPromptTemplate.from_template("""
                            ë„ˆëŠ” 20ë…„ ê²½ë ¥ì˜ ë”°ëœ»í•˜ê³  ìœ ëŠ¥í•œ ë…¸ë™ë²• ì „ë¬¸ ë³€í˜¸ì‚¬ë‹¤. ì˜ë¢°ì¸ì˜ [ìƒí™©]ê³¼ [ê´€ë ¨ ì¡°í•­]ì„ ë°”íƒ•ìœ¼ë¡œ ì•„ë˜ í˜•ì‹ì— ë§ì¶° ìƒë‹´ ë‚´ìš©ì„ ì‘ì„±í•˜ë¼.

                            [ì˜ë¢°ì¸ ìƒí™©]
                            {user_input}

                            [ê´€ë ¨ ë²•ë¥  ì¡°í•­]
                            {docs_context}

                            [ì‘ì„± í˜•ì¹™ (ë°˜ë“œì‹œ ì¤€ìˆ˜)]
                            1. **ğŸ’• ë”°ëœ»í•œ ìœ„ë¡œ**: ì˜ë¢°ì¸ì˜ í˜ë“  ìƒí™©ì— ëŒ€í•´ ì§„ì‹¬ ì–´ë¦° ê³µê°ê³¼ ìœ„ë¡œì˜ ë§ì„ ê±´ë„¤ë¼. (1-2ë¬¸ì¥)
                            2. **âš–ï¸ ë²•ë¥  ìš”ì•½ (ìŸì ë³„ êµ¬ë¶„)**: ìƒí™©ì— ë³µí•©ì ì¸ ë¬¸ì œ(ì˜ˆ: ë¶€ë‹¹í•´ê³  + ì„ê¸ˆì²´ë¶ˆ)ê°€ ìˆë‹¤ë©´, **1. ë¶€ë‹¹í•´ê³ , 2. ì„ê¸ˆì²´ë¶ˆ** ê³¼ ê°™ì´ ë²ˆí˜¸ë¥¼ ë§¤ê²¨ ê°ê° ëª…í™•íˆ ì§„ë‹¨í•˜ë¼.
                            3. **ğŸ›¡ï¸ ì¡°ì–¸ ë° ëŒ€ì²˜**: ê° ìŸì ë³„ë¡œ ì˜ë¢°ì¸ì´ ë‹¹ì¥ ì·¨í•´ì•¼ í•  í–‰ë™(ì¦ê±° í™•ë³´, ì‹ ê³  ì ˆì°¨ ë“±)ì„ êµ¬ì²´ì ìœ¼ë¡œ ì•ˆë‚´í•˜ë¼.
                            4. **âœ… ìŠ¤ìŠ¤ë¡œ ì²´í¬í•˜ê¸°**: ìŠ¹ì†Œ ê°€ëŠ¥ì„±ì„ íŒë‹¨í•˜ê¸° ìœ„í•œ í•µì‹¬ ì§ˆë¬¸ 5ê°€ì§€ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë‚˜ì—´í•˜ë¼.
                            5. **ğŸ“œ ê·¼ê±° ë²•ë ¹**: ìœ„ ìƒë‹´ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ë²•ë¥  ì¡°í•­ ë²ˆí˜¸ì™€ ëª…ì¹­ì„ ëª…ì‹œí•˜ë¼.

                            [ì–´ì¡°]
                            ì „ë¬¸ì ì´ì§€ë§Œ, ì˜ë¢°ì¸ì„ ê°€ì¡±ì²˜ëŸ¼ ê±±ì •í•˜ëŠ” ë”°ëœ»í•˜ê³  ì •ì¤‘í•œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ë¼.
                            """)
                            
                            llm = LLMFactory.create_llm("openai", temperature=0.3)
                            chain = lawyer_prompt | llm
                            
                            # Streaming the response
                            message_placeholder = st.empty()
                            full_response = ""
                            
                            # Use chain.stream for token-by-token update
                            for chunk in chain.stream({
                                "user_input": user_input,
                                "docs_context": docs_context
                            }):
                                if chunk.content:
                                    full_response += chunk.content
                                    message_placeholder.markdown(full_response + "â–Œ")
                            
                            # Final update without cursor
                            message_placeholder.markdown(full_response)
                            
                        except Exception as e:
                            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            except Exception as e:
                import traceback
                st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.code(traceback.format_exc())

if __name__ == "__main__":
    main()
